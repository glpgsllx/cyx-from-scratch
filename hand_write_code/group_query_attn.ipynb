{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:13:28.303173Z",
     "start_time": "2024-07-04T04:13:27.448972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn"
   ],
   "id": "cc30c71c61fbe021",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-04T04:28:17.491717Z",
     "start_time": "2024-07-04T04:28:17.480258Z"
    }
   },
   "source": [
    "class GroupQueryAttn(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_groups):\n",
    "        super(GroupQueryAttn, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.n_groups = n_groups\n",
    "        \n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads_groups = self.n_heads // self.n_groups\n",
    "        self.head_dim = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, self.n_groups * self.head_dim)\n",
    "        self.w_v = nn.Linear(d_model, self.n_groups * self.head_dim)\n",
    "        self.w_combine = nn.Linear(d_model, d_model)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def expand(self, data):\n",
    "        batch, time = data.shape[0], data.shape[2]\n",
    "        data = data[:,:,None,:,:].expand(batch, self.n_groups, self.n_heads_groups, time, self.head_dim).contiguous()\n",
    "        data = data.view(batch, self.n_groups * self.n_heads_groups, time, self.head_dim)\n",
    "        return data\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        q = self.w_q(q)\n",
    "        k = self.w_k(k)\n",
    "        v = self.w_v(v)\n",
    "        \n",
    "        batch = q.shape[0]\n",
    "        q = q.view(batch, -1, self.n_groups * self.n_heads_groups, self.head_dim).permute(0, 2, 1, 3)\n",
    "        print(q.shape)\n",
    "        k = k.view(batch, -1, self.n_groups, self.head_dim).permute(0, 2, 1, 3)\n",
    "        print(k.shape)\n",
    "        v = v.view(batch, -1, self.n_groups, self.head_dim).permute(0, 2, 1, 3)\n",
    "        print(v.shape)\n",
    "        \n",
    "        k = self.expand(k)\n",
    "        print(k.shape)\n",
    "        v = self.expand(v)\n",
    "        print(v.shape)\n",
    "        score = q @ k.transpose(2, 3) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -1e9)\n",
    "        score = self.softmax(score) @ v\n",
    "        score = score.permute(0, 2, 1, 3).contiguous().view(batch, -1, self.d_model)\n",
    "        print(score.shape)\n",
    "        output = self.w_combine(score)\n",
    "        print(output.shape)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:28:17.865158Z",
     "start_time": "2024-07-04T04:28:17.847575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.randn(1, 32, 16)  # bs, len, dim\n",
    "X.shape"
   ],
   "id": "5566d7796070eec9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:28:18.129231Z",
     "start_time": "2024-07-04T04:28:18.124458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_model = 16\n",
    "n_head = 8\n",
    "n_groups = 4"
   ],
   "id": "e147fe5aadfecab9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T04:28:18.434538Z",
     "start_time": "2024-07-04T04:28:18.418270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention = GroupQueryAttn(d_model, n_head, n_groups)\n",
    "output = attention(X, X, X)\n",
    "print(output, output.shape)"
   ],
   "id": "fb90f2c243d78be8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 32, 2])\n",
      "torch.Size([1, 4, 32, 2])\n",
      "torch.Size([1, 4, 32, 2])\n",
      "torch.Size([1, 8, 32, 2])\n",
      "torch.Size([1, 8, 32, 2])\n",
      "torch.Size([1, 32, 16])\n",
      "torch.Size([1, 32, 16])\n",
      "tensor([[[ 0.1481, -0.2424, -0.0826,  0.1685,  0.1371, -0.1359,  0.2079,\n",
      "          -0.1224, -0.1352, -0.1071,  0.0779,  0.0281, -0.0310, -0.0415,\n",
      "          -0.0713,  0.2314],\n",
      "         [ 0.0865, -0.1925, -0.0885,  0.1693,  0.1754, -0.1811,  0.2080,\n",
      "          -0.0356, -0.1177, -0.1253,  0.0495,  0.0947, -0.0344, -0.0781,\n",
      "           0.0077,  0.2971],\n",
      "         [ 0.1401, -0.2101, -0.1021,  0.1176,  0.0850, -0.1783,  0.1779,\n",
      "          -0.0417, -0.1863, -0.0942,  0.1125,  0.0209, -0.0358, -0.0556,\n",
      "          -0.0383,  0.2139],\n",
      "         [ 0.0888, -0.1820, -0.1283,  0.1406,  0.1148, -0.1897,  0.2224,\n",
      "          -0.0355, -0.1422, -0.0877,  0.1177,  0.0312, -0.0563, -0.0675,\n",
      "          -0.0258,  0.2513],\n",
      "         [ 0.1265, -0.1809, -0.0800,  0.1238,  0.1163, -0.1718,  0.1594,\n",
      "          -0.0184, -0.1565, -0.0904,  0.0933,  0.0616, -0.0183, -0.0897,\n",
      "           0.0046,  0.2285],\n",
      "         [ 0.1160, -0.1937, -0.1091,  0.1386,  0.1062, -0.1731,  0.2146,\n",
      "          -0.0574, -0.1143, -0.0911,  0.1179,  0.0220, -0.0337, -0.0464,\n",
      "          -0.0475,  0.2369],\n",
      "         [ 0.1174, -0.2429, -0.0728,  0.1245,  0.1462, -0.0958,  0.2105,\n",
      "          -0.0891, -0.1356, -0.0988,  0.0269,  0.0687, -0.0192, -0.0698,\n",
      "          -0.0465,  0.2298],\n",
      "         [ 0.1207, -0.2201, -0.0891,  0.1641,  0.1647, -0.1529,  0.2157,\n",
      "          -0.0826, -0.1445, -0.1186,  0.0585,  0.0598, -0.0162, -0.0672,\n",
      "          -0.0426,  0.2790],\n",
      "         [ 0.1174, -0.2147, -0.1276,  0.1561,  0.1603, -0.1979,  0.2616,\n",
      "          -0.0332, -0.1505, -0.1295,  0.0660,  0.0247,  0.0066, -0.0502,\n",
      "          -0.0712,  0.3323],\n",
      "         [ 0.1169, -0.2165, -0.0901,  0.1441,  0.1387, -0.1506,  0.2160,\n",
      "          -0.0657, -0.1682, -0.0900,  0.0769,  0.0556, -0.0149, -0.0838,\n",
      "          -0.0269,  0.2614],\n",
      "         [ 0.1188, -0.2143, -0.0894,  0.1540,  0.1999, -0.1334,  0.2006,\n",
      "          -0.0880, -0.1453, -0.1237,  0.0374,  0.0819, -0.0126, -0.0893,\n",
      "          -0.0257,  0.2989],\n",
      "         [ 0.1083, -0.1921, -0.1233,  0.1784,  0.1585, -0.1955,  0.2394,\n",
      "          -0.0542, -0.1305, -0.1164,  0.0897,  0.0321, -0.0190, -0.0576,\n",
      "          -0.0553,  0.2979],\n",
      "         [ 0.1079, -0.1713, -0.1138,  0.1625,  0.1593, -0.1778,  0.2237,\n",
      "          -0.0375, -0.1234, -0.1139,  0.0753,  0.0590, -0.0381, -0.0756,\n",
      "          -0.0241,  0.2633],\n",
      "         [ 0.0922, -0.1667, -0.1298,  0.1391,  0.1222, -0.1886,  0.2180,\n",
      "          -0.0310, -0.1406, -0.0879,  0.1302,  0.0391, -0.0461, -0.0759,\n",
      "          -0.0239,  0.2676],\n",
      "         [ 0.1095, -0.2143, -0.1156,  0.1579,  0.1640, -0.1872,  0.2199,\n",
      "          -0.0463, -0.1416, -0.1339,  0.0593,  0.0600, -0.0357, -0.0525,\n",
      "          -0.0308,  0.3021],\n",
      "         [ 0.1078, -0.2263, -0.1235,  0.1622,  0.1508, -0.1868,  0.2521,\n",
      "          -0.0499, -0.1482, -0.1168,  0.0745,  0.0332, -0.0250, -0.0487,\n",
      "          -0.0556,  0.3026],\n",
      "         [ 0.0960, -0.2321, -0.1076,  0.1903,  0.1794, -0.1714,  0.2515,\n",
      "          -0.0939, -0.1552, -0.1260,  0.0747,  0.0605, -0.0656, -0.0638,\n",
      "          -0.0333,  0.3096],\n",
      "         [ 0.1715, -0.2496, -0.0955,  0.1668,  0.1621, -0.1459,  0.1793,\n",
      "          -0.1286, -0.1232, -0.1464,  0.0478,  0.0140, -0.0196, -0.0126,\n",
      "          -0.1031,  0.2539],\n",
      "         [ 0.1012, -0.1648, -0.0887,  0.1212,  0.0864, -0.1971,  0.1890,\n",
      "           0.0019, -0.1854, -0.0711,  0.1269,  0.0349, -0.0139, -0.0986,\n",
      "          -0.0083,  0.2374],\n",
      "         [ 0.1409, -0.1969, -0.1115,  0.1734,  0.1361, -0.1850,  0.2150,\n",
      "          -0.0707, -0.1666, -0.1117,  0.1013,  0.0225, -0.0122, -0.0579,\n",
      "          -0.0657,  0.2599],\n",
      "         [ 0.1428, -0.1849, -0.1413,  0.1374,  0.0751, -0.2423,  0.1749,\n",
      "          -0.0255, -0.2086, -0.0955,  0.1644, -0.0204, -0.0392, -0.0465,\n",
      "          -0.0565,  0.2450],\n",
      "         [ 0.1528, -0.2218, -0.1017,  0.1264,  0.0840, -0.2083,  0.1791,\n",
      "          -0.0240, -0.2224, -0.0991,  0.1209,  0.0027, -0.0043, -0.0572,\n",
      "          -0.0506,  0.2511],\n",
      "         [ 0.1286, -0.2055, -0.1145,  0.1461,  0.0820, -0.2365,  0.2328,\n",
      "          -0.0012, -0.1976, -0.1087,  0.1228, -0.0010, -0.0091, -0.0442,\n",
      "          -0.0595,  0.2737],\n",
      "         [ 0.1291, -0.1836, -0.0880,  0.1300,  0.0522, -0.2327,  0.1401,\n",
      "          -0.0170, -0.2006, -0.0669,  0.1849,  0.0126, -0.0638, -0.0763,\n",
      "           0.0087,  0.2181],\n",
      "         [ 0.1057, -0.1872, -0.1213,  0.1629,  0.1033, -0.2116,  0.2369,\n",
      "          -0.0359, -0.1081, -0.0987,  0.1192,  0.0009, -0.0124, -0.0335,\n",
      "          -0.0730,  0.2640],\n",
      "         [ 0.1443, -0.2071, -0.1142,  0.1618,  0.1708, -0.1990,  0.1923,\n",
      "          -0.0480, -0.1971, -0.1425,  0.0725,  0.0555, -0.0130, -0.0727,\n",
      "          -0.0343,  0.3114],\n",
      "         [ 0.1090, -0.2070, -0.1354,  0.1482,  0.1469, -0.1894,  0.2166,\n",
      "          -0.0573, -0.1870, -0.0913,  0.1116,  0.0315, -0.0289, -0.0842,\n",
      "          -0.0322,  0.2999],\n",
      "         [ 0.0856, -0.1826, -0.1526,  0.1487,  0.1524, -0.2243,  0.2421,\n",
      "          -0.0059, -0.1466, -0.1372,  0.0940,  0.0426, -0.0414, -0.0491,\n",
      "          -0.0430,  0.3426],\n",
      "         [ 0.1307, -0.2264, -0.1144,  0.1261,  0.0559, -0.1804,  0.2177,\n",
      "          -0.0641, -0.1443, -0.0864,  0.1306, -0.0160, -0.0425, -0.0118,\n",
      "          -0.0806,  0.1959],\n",
      "         [ 0.1231, -0.1722, -0.1374,  0.1682,  0.1676, -0.1813,  0.2099,\n",
      "          -0.0808, -0.1488, -0.0833,  0.1266,  0.0265, -0.0237, -0.0973,\n",
      "          -0.0336,  0.2901],\n",
      "         [ 0.1405, -0.2035, -0.1140,  0.1736,  0.1778, -0.1686,  0.1885,\n",
      "          -0.0878, -0.1244, -0.1338,  0.0669,  0.0516, -0.0537, -0.0489,\n",
      "          -0.0389,  0.2676],\n",
      "         [ 0.1192, -0.2319, -0.1027,  0.1440,  0.1270, -0.1607,  0.2345,\n",
      "          -0.0665, -0.1573, -0.0986,  0.0747,  0.0271, -0.0139, -0.0540,\n",
      "          -0.0576,  0.2598]]], grad_fn=<ViewBackward0>) torch.Size([1, 32, 16])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "638b2a18163fa41f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
